{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced ML: Домашнее задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    " - подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    " - возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    " - расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyDecoder:\n",
    "    _eng_alphabet = string.ascii_lowercase + ' '\n",
    "    _rus_alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "    \n",
    "    def __init__(self, language='rus', n_gram_len=1):\n",
    "        self.n_gram_len = n_gram_len\n",
    "        if language == 'rus':\n",
    "            self._alphabet = FrequencyDecoder._rus_alphabet\n",
    "        elif language == 'eng':\n",
    "            self._alphabet = FrequencyDecoder._eng_alphabet\n",
    "        else:\n",
    "            raise ValueError('Wrong language name.')\n",
    "    \n",
    "    def train(self, text):\n",
    "        text = ''.join([char for char in text.lower() if char in self._alphabet])\n",
    "        splitted_text = [text[i:i+self.n_gram_len] for i in range(len(text) - self.n_gram_len + 1)]\n",
    "        self._frequency_dict = Counter(splitted_text)\n",
    "        sort_indx = np.argsort(list(self._frequency_dict.values()))[::-1]\n",
    "        self._alphabet_sorted = np.array(list(self._frequency_dict.keys()))[sort_indx]\n",
    "    \n",
    "    def decode(self, text):\n",
    "        original_len = len(text)\n",
    "        text += ' ' * (original_len % self.n_gram_len)\n",
    "        splitted_text = [text[i:i+self.n_gram_len] for i in range(0, len(text) - self.n_gram_len + 1, \n",
    "                                                                  self.n_gram_len)]\n",
    "        decoded_frequency_dict = Counter(splitted_text)\n",
    "        sort_indx = np.argsort(list(decoded_frequency_dict.values()))[::-1]\n",
    "        decoded_alphabet_sorted = np.array(list(decoded_frequency_dict.keys()))[sort_indx]\n",
    "        transtable_size = min(len(decoded_alphabet_sorted), len(self._alphabet_sorted))\n",
    "        transtable = {}\n",
    "        for i in range(transtable_size):\n",
    "            transtable[decoded_alphabet_sorted[i]] = self._alphabet_sorted[i]\n",
    "        return ''.join([transtable[n_gram] for n_gram in splitted_text])[:original_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubstitutionEncoder:\n",
    "    _eng_alphabet = string.ascii_lowercase + ' '\n",
    "    _rus_alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "    \n",
    "    def __init__(self, language='rus'):\n",
    "        if language == 'rus':\n",
    "            self._alphabet = SubstitutionEncoder._rus_alphabet\n",
    "        elif language == 'eng':\n",
    "            self._alphabet = SubstitutionEncoder._eng_alphabet\n",
    "        else:\n",
    "            raise ValueError('Wrong language name.')\n",
    "        self._permutation = ''.join(random.sample(self._alphabet,len(self._alphabet)))\n",
    "        self._transtable = str.maketrans(self._alphabet, self._permutation)\n",
    "        \n",
    "    def encode(self, text):\n",
    "        encoded_text = text.lower().translate(self._transtable)\n",
    "        encoded_text = ''.join([char for char in encoded_text if char in self._permutation])\n",
    "        return encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyEvaluator:\n",
    "    _eng_alphabet = string.ascii_lowercase + ' '\n",
    "    _rus_alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "    \n",
    "    def __init__(self, language='rus'):\n",
    "        if language == 'rus':\n",
    "            self._alphabet = AccuracyEvaluator._rus_alphabet\n",
    "        elif language == 'eng':\n",
    "            self._alphabet = AccuracyEvaluator._eng_alphabet\n",
    "        else:\n",
    "            raise ValueError('Wrong language name.')\n",
    "            \n",
    "    def evaluate(self, original_text, decoded_text):\n",
    "        original_text = np.array([char for char in original_text.lower() if char in self._alphabet])\n",
    "        decoded_text = np.array(list(decoded_text))\n",
    "        return (original_text == decoded_text).sum()/len(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/AnnaKarenina.txt', 'r') as f:\n",
    "    train_text = f.read()\n",
    "with open('data/WarAndPeace.txt', 'r') as f:\n",
    "    train_text += f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_one_gram = FrequencyDecoder('rus')\n",
    "decoder_one_gram.train(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/platonov.txt', 'r') as f:\n",
    "    test_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \n",
      "Трава опять отросла по набитым грунтовым дорогам гражданской войны, потому что война прекратилась. В мире, по губерниям снова стало тихо и малолюдно: некоторые люди умерли в боях, многие лечились от ран и отдыхали у родных, забывая в долгих снах тяжелую работу войны, а кое-кто из демобилизованных еще не успел вернуться домой и шел теперь в старой шинели, с походной сумкой, в мягком шлеме или овечьей шапке, – шел по густой, незнакомой траве, которую раньше не было времени видеть, а может быть – она просто была затоптана походами и не росла тогда.\n"
     ]
    }
   ],
   "source": [
    "print('Original text: ')\n",
    "print(test_text[:551])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SubstitutionEncoder('rus')\n",
    "encoded_text = encoder.encode(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: \n",
      "щхзезрлцфщнрлщхлгтзрцлрйзкощжчрвхяйщлежчрслхлвзчрвхзбсзйгыларелайжрцлщлчярпщлрелайзрцх ыхзщотзгнрерчох рцлрвяк хйофчргйлезргщзтлрщодлрорчзтлтисйлрй ылщлхж ртисоряч хторерклфдрчйлво рт потогнрлщрхзйрорлщсждзторярхлсйждрузкжезфрерслтводргйздрщфб тяирхзклщярелайжрзрыл ыщлроурс члкотоулезййждр ъ рй рягц тре хйящнгфрслчларорш трщ ц хнрергщзхларшой торгрцлдлсйларгячыларерчфвылчршт ч роторле пн аршзцы ррш трцлрвягщларй уйзылчларщхзе рылщлхяирхзйнш рй ркжтлрех ч йореос щнрзрчлб щркжщнррлйзрцхлгщлркжтзрузщлцщзйзрцлдлсзчорорй рхлгтзрщлвсз\n"
     ]
    }
   ],
   "source": [
    "print('Encoded text: ')\n",
    "print(encoded_text[:534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = decoder_one_gram.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text: \n",
      "твара опгть отвосла по иазнтяд ывуиторяд мовоыад ывашмаискоб робия потоду что робиа пвекватнлась р днве по ыузевингд сиора стало тнхо н далолэмио иекотовяе лэмн удевлн р зогх диоыне лечнлнсь от ваи н отмяхалн у вомиях жазяраг р молынх сиах тгшелуэ вазоту робия а коекто нж медознлнжораииях еце ие успел ревиутьсг модоб н йел тепевь р ставоб йниелн с похомиоб судкоб р дгыкод йледе нлн оречьеб йапке  йел по ыустоб иежиакодоб тваре котовуэ ваиьйе ие зяло рведеин рнметь а дошет зять  оиа пвосто зяла жатоптаиа похомадн н ие восла тоыма\n"
     ]
    }
   ],
   "source": [
    "print('Decoded text: ')\n",
    "print(decoded_text[:534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  64.718%.\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {AccuracyEvaluator(\"rus\").evaluate(test_text, decoded_text) * 100 : 0.5}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    " - подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    " - проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_bigram = FrequencyDecoder('rus', 2)\n",
    "decoder_bigram.train(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = decoder_bigram.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text: \n",
      "слоб пхаяс бголоим пов нньв ивт чаоятьивя омевсьт раым лвал  сл еге го дресаа орап п эмараатседа с миз вовт ч   наепо казао енерол ха и ойерочсва  кластеб вочей чю яни  темйс мкаца ввоедродатоаврасяи голсчиро чскй егчеетльзани тогпу хо почецеже шмораемди сл егужнотитча ыля либыасылть легчевн в к чмнал с   атария  дл  оаралолыв   б ткоанл армиали исовоесвл о палаь  ттннк дарвою  оротовинсазарутлузн рнеовт иксть  кие я дл олравиногоомщеск ллю в келруа лялиоди туактауж мсндеелга бтопое локоа льсе гвсхаенпое  цй сьи и  кскпрсеолевес\n"
     ]
    }
   ],
   "source": [
    "print('Decoded text: ')\n",
    "print(decoded_text[:534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  14.317%.\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {AccuracyEvaluator(\"rus\").evaluate(test_text, decoded_text) * 100 : 0.5}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    " - предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    " - реализуйте и протестируйте его, убедитесь, что результаты улучшились."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что текст это цепь Маркова, где буквы являются состояниями. Обучим матрицу переходов между буквами на тренировочном тексте. Далее для каждой перестановки, с помощью которой можно осуществить расшифровку, можно найти правдоподобие этой перестановки, перемножив вероятности всех переходов в расшифрованном тексте. Соответственно можно применить MCMC-семплирование для выбора перестановки из распределения, заданного этим правдоподобием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCDecoder:\n",
    "    _eng_alphabet = string.ascii_lowercase + ' '\n",
    "    _rus_alphabet = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "    \n",
    "    def __init__(self, language='rus'):\n",
    "        if language == 'rus':\n",
    "            self._alphabet = MCMCDecoder._rus_alphabet\n",
    "        elif language == 'eng':\n",
    "            self._alphabet = MCMCDecoder._eng_alphabet\n",
    "        else:\n",
    "            raise ValueError('Wrong language name.')\n",
    "        self._char_to_idx = {char: idx for idx, char in enumerate(self._alphabet)}\n",
    "        self._transition_matrix = np.zeros((len(self._alphabet), len(self._alphabet)))\n",
    "    \n",
    "    def train(self, text):\n",
    "        text = ''.join([char for char in text.lower() if char in self._alphabet])\n",
    "        for i in range(len(text) - 1):\n",
    "            self._transition_matrix[self._char_to_idx[text[i]], self._char_to_idx[text[i+1]]] += 1\n",
    "        self._transition_matrix = np.clip(self._transition_matrix, 1, None)\n",
    "        self._transition_matrix = (np.log(self._transition_matrix).T \n",
    "                                   - np.log(self._transition_matrix.sum(axis=1))).T\n",
    "        \n",
    "    def _translate(self, text, permutation):\n",
    "        transtable = str.maketrans(self._alphabet, ''.join(permutation))\n",
    "        return text.translate(transtable)\n",
    "        \n",
    "    def _evaluate_log_likelihood(self, text, permutation):\n",
    "        text = self._translate(text, permutation)\n",
    "        log_likelihood = 0\n",
    "        for i in range(len(text) - 1):\n",
    "            log_likelihood += self._transition_matrix[self._char_to_idx[text[i]], self._char_to_idx[text[i+1]]]\n",
    "        return log_likelihood\n",
    "    \n",
    "    def decode(self, text, initial_permutation=None, n_iters=10000, seed=None, restart_period=None):\n",
    "        if initial_permutation is None:\n",
    "            permutation = np.array(list(self._alphabet))\n",
    "            random.shuffle(permutation)\n",
    "        else:\n",
    "            permutation = initial_permutation\n",
    "        current_log_likelihood = self._evaluate_log_likelihood(text, permutation)\n",
    "        best_log_likelihood = current_log_likelihood\n",
    "        best_permutation = permutation.copy()\n",
    "        for i in range(n_iters):\n",
    "            if restart_period is not None and i % restart_period == 0:\n",
    "                random.shuffle(permutation)\n",
    "                current_log_likelihood = self._evaluate_log_likelihood(text, permutation)\n",
    "            swap_idx = random.sample(range(len(self._alphabet)), 2)\n",
    "            permutation[swap_idx[0]], permutation[swap_idx[1]] = \\\n",
    "                permutation[swap_idx[1]], permutation[swap_idx[0]]\n",
    "            new_log_likelihood = self._evaluate_log_likelihood(text, permutation)\n",
    "            if new_log_likelihood >= current_log_likelihood:\n",
    "                current_log_likelihood = new_log_likelihood\n",
    "                if new_log_likelihood > best_log_likelihood:\n",
    "                    best_log_likelihood = new_log_likelihood\n",
    "                    best_permutation = permutation.copy()\n",
    "            else:\n",
    "                if random.random() < np.exp(new_log_likelihood - current_log_likelihood):\n",
    "                    current_log_likelihood = new_log_likelihood\n",
    "                else:\n",
    "                    permutation[swap_idx[0]], permutation[swap_idx[1]] = \\\n",
    "                        permutation[swap_idx[1]], permutation[swap_idx[0]]\n",
    "        return self._translate(text, best_permutation), best_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_decoder = MCMCDecoder('rus')\n",
    "mcmc_decoder.train(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text, _ = mcmc_decoder.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text: \n",
      "трава опять отросла по набитым грунтовым дорогам гражданской войны потому что война прекратилась в мире по губерниям снова стало тихо и малолюдно некоторые люди умерли в боях многие лечились от ран и отдыхали у родных забывая в долгих снах тяжелую работу войны а коекто из демобилизованных еще не успел вернуться домой и шел теперь в старой шинели с походной сумкой в мягком шлеме или овечьей шапке  шел по густой незнакомой траве которую раньше не было времени видеть а может быть  она просто была затоптана походами и не росла тогда\n"
     ]
    }
   ],
   "source": [
    "print('Decoded text: ')\n",
    "print(decoded_text[:534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  100.0%.\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {AccuracyEvaluator(\"rus\").evaluate(test_text, decoded_text) * 100 : 0.5}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расшифруйте сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded message\n",
      "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\n"
     ]
    }
   ],
   "source": [
    "print('Encoded message')\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведём сначала в алфавит, аналогичный тому, в котором расшифровывается сообщение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_letters = ''.join(set(message))\n",
    "rus_letters = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '[:len(encoded_letters)]\n",
    "transtable = str.maketrans(encoded_letters, rus_letters)\n",
    "message = message.translate(transtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_decoded, _ = mcmc_decoder.decode(message, n_iters=600000, restart_period=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded message: \n",
      "если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж\n"
     ]
    }
   ],
   "source": [
    "print('Decoded message: ')\n",
    "print(message_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бонус: какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данную модель можно использовать например для восстановления исходного текста в ситуации когда сбивается кодировка, при условии, что каждому символу в неправильной кодировке соответствует один символ в правильной."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
